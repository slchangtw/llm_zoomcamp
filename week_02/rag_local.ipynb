{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, ensure you have the Docker images up and running using the `docker-compose` file provided in this folder. To do so, run the following command in the terminal:\n",
    "\n",
    "```bash\n",
    "docker-compose up\n",
    "```\n",
    "\n",
    "In a new terminal, run the following command to download the pre-trained model `Phi-3`:\n",
    "\n",
    "```bash\n",
    "docker exec -it ollama ollama pull phi3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shun_lung_chang/python_projects/llm_zoomcamp/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from openai import OpenAI\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a document search engine using Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:03<00:00, 288.79it/s]\n"
     ]
    }
   ],
   "source": [
    "docs_url = \"https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1\"\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course[\"course\"]\n",
    "\n",
    "    for doc in course[\"documents\"]:\n",
    "        doc[\"course\"] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "es_client = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\"number_of_shards\": 1, \"number_of_replicas\": 0},\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query: str, course: str, es_client: Elasticsearch, index_name: str):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\",\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\"term\": {\"course\": course}},\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "\n",
    "    result_docs = []\n",
    "\n",
    "    for hit in response[\"hits\"][\"hits\"]:\n",
    "        result_docs.append(hit[\"_source\"])\n",
    "\n",
    "    return result_docs\n",
    "\n",
    "\n",
    "def build_prompt(question: str, response_docs: list[dict[str, str]]) -> str:\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database. Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in response_docs:\n",
    "        context += f\"Section: {doc['section']}\\n\"\n",
    "        context += f\"Question: {doc['question']}\\n\"\n",
    "        context += f\"Answer: {doc['text']}\\n\\n\"\n",
    "\n",
    "    return prompt_template.format(question=question, context=context)\n",
    "\n",
    "\n",
    "def llm(prompt: str, client: OpenAI, model: str = \"phi3\") -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def rag(\n",
    "    query: str,\n",
    "    course: str,\n",
    "    model_name: str,\n",
    "    openai_client: OpenAI,\n",
    "    es_client: Elasticsearch,\n",
    "    index_name: str,\n",
    ") -> str:\n",
    "    search_results = elastic_search(query, course, es_client, index_name)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt, openai_client, model_name)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1/\",\n",
    "    api_key=\"ollama\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The expected duration of each module in the MLOps zoomcamp is approximately 3 months, with an additional time frame for completing activities within individual modules such as experiment tracking and capstone projects that can extend up to a total of around 7-8 weeks (including possible extensions). This does not include preparation or other personal study outside of these guidelines.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the expected duration of the course MLOps zoomcamp?\"\n",
    "course = \"mlops-zoomcamp\"\n",
    "model = \"phi3\"\n",
    "rag(question, course, model, openai_client, es_client, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
