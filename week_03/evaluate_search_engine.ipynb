{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running this notebook, ensure you have started an Elasticsearch instance using Docker. To do this, run the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "docker run -it \\\n",
    "    --rm \\\n",
    "    --name elasticsearch \\\n",
    "    -p 9200:9200 \\\n",
    "    -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.4.3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the embbeding dimention from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shun_lung_chang/python_projects/llm_zoomcamp/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"multi-qa-MiniLM-L6-cos-v1\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "embedding_dim = model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing an index in ElasticSearch with the embedding dimention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_client = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\"number_of_shards\": 1, \"number_of_replicas\": 0},\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": embedding_dim,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\",\n",
    "            },\n",
    "            \"text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": embedding_dim,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\",\n",
    "            },\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": embedding_dim,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\",\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building embeddings for the documents and storing them in the Elasticsearch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"documents-with-ids.json\", \"rt\") as f_in:\n",
    "    documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [02:37<00:00,  6.03it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    question = doc[\"question\"]\n",
    "    text = doc[\"text\"]\n",
    "    question_text = f\"{question} {text}\"\n",
    "\n",
    "    doc[\"question_vector\"] = model.encode(question)\n",
    "    doc[\"text_vector\"] = model.encode(text)\n",
    "    doc[\"question_text_vector\"] = model.encode(question_text)\n",
    "\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Declare search functions\n",
    "\n",
    "The search functions will take a query and return the most similar documents to the query. We will use question, text and question+text from the index to search for the most similar documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(\n",
    "    field: str, vector: np.array, course: str, k: int = 5\n",
    ") -> list[str, str]:\n",
    "    \"\"\"\n",
    "    Search for the k nearest neighbors in the Elasticsearch index using\n",
    "    the given field, vector, and course.\n",
    "    \"\"\"\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": k,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\"term\": {\"course\": course}},\n",
    "    }\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"],\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(index=index_name, body=search_query)\n",
    "\n",
    "    return [hit[\"_source\"] for hit in es_results[\"hits\"][\"hits\"]]\n",
    "\n",
    "\n",
    "def question_vector_knn(doc: dict[str, str], k: int) -> dict:\n",
    "    \"\"\"Retrieve relevant texts by question vector.\"\"\"\n",
    "    question = doc[\"question\"]\n",
    "    course = doc[\"course\"]\n",
    "\n",
    "    question_vector = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn(\"question_vector\", question_vector, course, k)\n",
    "\n",
    "\n",
    "def text_vector_knn(doc: dict[str, str], k: int) -> dict:\n",
    "    \"\"\"Retrieve relevant texts by text vector.\"\"\"\n",
    "    question = doc[\"question\"]\n",
    "    course = doc[\"course\"]\n",
    "\n",
    "    question_vector = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn(\"text_vector\", question_vector, course, k)\n",
    "\n",
    "\n",
    "def question_text_vector_knn(doc: dict[str, str], k: int) -> dict:\n",
    "    \"\"\"Retrieve relevant texts by both question and text vectors.\"\"\"\n",
    "    question = doc[\"question\"]\n",
    "    course = doc[\"course\"]\n",
    "\n",
    "    question_vector = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn(\"question_text_vector\", question_vector, course, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Course - What can I do before the course starts?',\n",
       " 'data-engineering-zoomcamp')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take an example document\n",
    "(documents[4][\"question\"], documents[4][\"course\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Course - What can I do before the course starts?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
       "  'id': '63394d91'},\n",
       " {'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'id': 'c02e79ef'},\n",
       " {'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'id': 'a482086d'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_vector_knn(documents[4], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'id': 'a482086d'},\n",
       " {'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'id': 'c02e79ef'},\n",
       " {'question': 'Course - I have registered for the Data Engineering Bootcamp. When can I expect to receive the confirmation email?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': \"You don't need it. You're accepted. You can also just start learning and submitting homework without registering. It is not checked against any registered list. Registration is just to gauge interest before the start date.\",\n",
       "  'id': '0bbf41ec'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector_knn(documents[4], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Course - Can I follow the course after it finishes?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       "  'id': 'a482086d'},\n",
       " {'question': 'Course - Can I still join the course after the start date?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       "  'id': '7842b56a'},\n",
       " {'question': 'Course - When will the course start?',\n",
       "  'course': 'data-engineering-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       "  'id': 'c02e79ef'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_text_vector_knn(documents[4], k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the performance of the search functions\n",
    "\n",
    "We use hit rate and mean reciprocal rank to evaluate the performance of the search functions. `relevance_total` is a boolean vector indicating whether the top k results contain the relevant document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_rate(relevance_total: list[list[bool]]) -> float:\n",
    "    count = 0\n",
    "    for line in relevance_total:\n",
    "        if True in line:\n",
    "            count += 1\n",
    "\n",
    "    return round(count / len(relevance_total), 4)\n",
    "\n",
    "\n",
    "def mrr(relevance_total: list[list[bool]]) -> float:\n",
    "    total_score = 0.0\n",
    "\n",
    "    for line in relevance_total:\n",
    "        for i, item in enumerate(line):\n",
    "            if item is True:\n",
    "                total_score += +1 / (i + 1)\n",
    "\n",
    "    return round(total_score / len(relevance_total), 4)\n",
    "\n",
    "\n",
    "def evaluate(ground_truth: list[dict], search_function: callable) -> dict[str, float]:\n",
    "    relevance_total = []\n",
    "\n",
    "    for doc in tqdm(ground_truth):\n",
    "        doc_id = doc[\"document\"]\n",
    "        results = search_function(doc, k=5)\n",
    "        relevance = [d[\"id\"] == doc_id for d in results]\n",
    "        relevance_total.append(relevance)\n",
    "\n",
    "    return {\n",
    "        \"hit_rate\": hit_rate(relevance_total),\n",
    "        \"mrr\": mrr(relevance_total),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ground truth data\n",
    "ground_truth = pd.read_csv(\"ground-truth-data.csv\").to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [01:19<00:00, 58.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.773071104387292, 'mrr': 0.6666810748505158}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_question_vector_knn = evaluate(ground_truth, question_vector_knn)\n",
    "performance_question_vector_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [01:19<00:00, 58.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.8286146531229739, 'mrr': 0.7062315395144454}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_text_vector_knn = evaluate(ground_truth, text_vector_knn)\n",
    "performance_text_vector_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [01:19<00:00, 58.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9172249837907932, 'mrr': 0.824306606152295}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_question_text_vector_knn = evaluate(ground_truth, question_text_vector_knn)\n",
    "performance_question_text_vector_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using custome scoring logic for ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_combined_cos_similarity(\n",
    "    vector: np.array, course: str, k: int = 5\n",
    ") -> list[str, str]:\n",
    "    \"\"\"\n",
    "    The custom logic computes the sum of the cosine similarities between the provided query vector and\n",
    "    three document vectors (question_vector, text_vector, and question_text_vector), plus a constant value of 1.\n",
    "    \"\"\"\n",
    "    search_query = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": [\n",
    "                    {\n",
    "                        \"script_score\": {\n",
    "                            \"query\": {\"term\": {\"course\": course}},\n",
    "                            \"script\": {\n",
    "                                \"source\": \"\"\"\n",
    "                                    cosineSimilarity(params.query_vector, 'question_vector') + \n",
    "                                    cosineSimilarity(params.query_vector, 'text_vector') + \n",
    "                                    cosineSimilarity(params.query_vector, 'question_text_vector') + \n",
    "                                    1\n",
    "                                \"\"\",\n",
    "                                \"params\": {\"query_vector\": vector},\n",
    "                            },\n",
    "                        }\n",
    "                    }\n",
    "                ],\n",
    "                \"filter\": {\"term\": {\"course\": course}},\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"],\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(index=index_name, body=search_query)\n",
    "\n",
    "    return [hit[\"_source\"] for hit in es_results[\"hits\"][\"hits\"]]\n",
    "\n",
    "\n",
    "def joint_vectors_search(doc: dict[str, str], k: int) -> dict:\n",
    "    question = doc[\"question\"]\n",
    "    course = doc[\"course\"]\n",
    "\n",
    "    question_vector = model.encode(question)\n",
    "\n",
    "    return elastic_search_combined_cos_similarity(question_vector, course, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [01:20<00:00, 57.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hit_rate': 0.9023125135076724, 'mrr': 0.804480945176861}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ground_truth, joint_vectors_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing text-only and embeddings-based search\n",
    "\n",
    "In the section, we will build a new index with only text and compare the performance of the search functions with the embeddings-based search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions-text-only'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\"number_of_shards\": 1, \"number_of_replicas\": 0},\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "index_name = \"course-questions-text-only\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 948/948 [00:03<00:00, 243.66it/s]\n"
     ]
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query: str, course: str, k: int = 5) -> list:\n",
    "    search_query = {\n",
    "        \"size\": k,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\",\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\"term\": {\"course\": course}},\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(index=index_name, body=search_query)\n",
    "\n",
    "    return [hit[\"_source\"] for hit in es_results[\"hits\"][\"hits\"]]\n",
    "\n",
    "\n",
    "def text_search(doc: dict[str, str], k: int) -> dict:\n",
    "    question = doc[\"question\"]\n",
    "    course = doc[\"course\"]\n",
    "\n",
    "    return elastic_search(question, course, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4627/4627 [00:27<00:00, 167.03it/s]\n"
     ]
    }
   ],
   "source": [
    "performance_text_search = evaluate(ground_truth, text_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of text-only search: {'hit_rate': 0.7396, 'mrr': 0.603}\n",
      "Performance of embedding search using question and text vectors: {'hit_rate': 0.9172, 'mrr': 0.8243}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Performance of text-only search: {performance_text_search}\\n\"\n",
    "    f\"Performance of embedding search using question and text vectors: {performance_question_text_vector_knn}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
