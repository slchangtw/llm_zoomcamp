{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url = \"https://github.com/DataTalksClub/llm-zoomcamp/blob/main/04-monitoring/data/results-gpt4o-mini.csv\"\n",
    "url = f\"{github_url}?raw=1\"\n",
    "df = pd.read_csv(url)\n",
    "df = df.iloc[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "/Users/shun_lung_chang/python_projects/llm_zoomcamp/.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"multi-qa-mpnet-base-dot-v1\"\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(-0.42244658)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.encode(df.iloc[0].answer_llm)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"answer_llm_embedding\"] = df[\"answer_llm\"].apply(embedding_model.encode)\n",
    "df[\"answer_orig_embedding\"] = df[\"answer_orig\"].apply(embedding_model.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [-0.42244658, -0.22485569, -0.32405874, -0.284...\n",
       "1      [-0.38068154, 0.047848597, -0.31510973, -0.210...\n",
       "2      [-0.058813937, -0.33736968, -0.36157575, 0.021...\n",
       "3      [-0.2275367, -0.00813403, -0.21719897, -0.1104...\n",
       "4      [-0.069693744, -0.500509, -0.1659841, 0.306661...\n",
       "                             ...                        \n",
       "295    [-0.2193304, 0.036429286, -0.22642444, 0.19385...\n",
       "296    [-0.4683964, 0.10411292, -0.19394597, 0.040338...\n",
       "297    [-0.35566193, 0.112268955, -0.28439155, 0.0621...\n",
       "298    [-0.23460822, -0.11785728, -0.20596509, 0.0863...\n",
       "299    [-0.12844159, -0.093136236, -0.20886736, 0.120...\n",
       "Name: answer_llm_embedding, Length: 300, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"answer_llm_embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dot_similarity\"] = df.apply(\n",
    "    lambda x: x[\"answer_llm_embedding\"] @ x[\"answer_orig_embedding\"], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(31.674306392669678)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"dot_similarity\"].quantile(0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(vector_1, vector_2):\n",
    "    vector_1_norm = vector_1 / np.linalg.norm(vector_1)\n",
    "    vector_2_norm = vector_2 / np.linalg.norm(vector_2)\n",
    "\n",
    "    return vector_1_norm @ vector_2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cosine_similarity\"] = df.apply(\n",
    "    lambda x: calculate_cosine_similarity(\n",
    "        x[\"answer_llm_embedding\"], x[\"answer_orig_embedding\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8362347781658173)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cosine_similarity\"].quantile(0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_score = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45454544954545456"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = df.iloc[10]\n",
    "scores = rouge_score.get_scores(row[\"answer_llm\"], row[\"answer_orig\"])[0]\n",
    "\n",
    "scores[\"rouge-1\"][\"f\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35490034990035496"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scores[\"rouge-1\"][\"f\"]+ scores[\"rouge-2\"][\"f\"] + scores[\"rouge-l\"][\"f\"]) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rouge2(row):\n",
    "    scores = rouge_score.get_scores(row[\"answer_llm\"], row[\"answer_orig\"])[0]\n",
    "    return scores[\"rouge-2\"][\"f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.20696501983423318)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"rouge2\"] = df.apply(calculate_rouge2, axis=1)\n",
    "df[\"rouge2\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
